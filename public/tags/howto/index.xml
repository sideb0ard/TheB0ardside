<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Howto on The B0ardside </title>
    <link>http://theb0ardside.com/tags/howto/index.xml</link>
    <language>en-us</language>
    <author>Thorsten Sideb0ard</author>
    <rights>Copyleft (c) 1974 - The Future, Thorsten Sideb0ard; nae rights reserved.</rights>
    <updated>2014-01-06 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>Joshua Davis - Beyond Play</title>
      <link>http://theb0ardside.com/joshua-davis-beyond-play</link>
      <pubDate>Mon, 06 Jan 2014 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/joshua-davis-beyond-play</guid>
      <description>&lt;p&gt;Wow. just wow&amp;hellip;&lt;/p&gt;

&lt;div class=&#34;video-container&#34;&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;//www.youtube.com/embed/LJS4fBjdPM4&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br/&gt;
&lt;a href=&#34;https://twitter.com/tackyy&#34;&gt;Tack&lt;/a&gt; turned me onto this guy the other day - i love him! Artist/Skater/Hacker - whats not to love?!&lt;/p&gt;

&lt;p&gt;This was following me and Tack&amp;rsquo;s &lt;a href=&#34;https://github.com/sideb0ard/Codetraxx&#34;&gt;Codetraxx&lt;/a&gt; project - which is working - we&amp;rsquo;re making music and synchronized via RabbitMQ as we set out to do - however we&amp;rsquo;ve hit a bit of a wall with the algorithmic math behind musical composition, so we&amp;rsquo;ve decided to focus on some mathematical hack nights for a while. Another friend of mine, &lt;a href=&#34;https://twitter.com/mattspendlove&#34;&gt;Matt Spendlove&lt;/a&gt;, had told me about &lt;a href=&#34;http://natureofcode.com/book/&#34;&gt;The Nature Of Code&lt;/a&gt; which i&amp;rsquo;ve been wanting to read, so I suggested we play with Processing - seems awesome already! So yeah, Codetraxx on hold for a while, and work on a couple of Processing projects for a while &amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Go Presentation</title>
      <link>http://theb0ardside.com/gopresentation</link>
      <pubDate>Mon, 30 Dec 2013 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/gopresentation</guid>
      <description>&lt;p&gt;More and more I&amp;rsquo;ve been dabbling with Go, which, mainly due to Hacker News, i&amp;rsquo;ve been reading so many good things about. The syntax is super easy to pick up, but the killer feature seems to be the concurrency primitives - the Go Functions and message passing Channels seem like a super tight, rock solid implementation of Hoare&amp;rsquo;s Communicating Sequential Processes. The following video is a really succinct walk through of building a concurent multi-protocol chat application ala Chat Roulette..&lt;/p&gt;

&lt;div class=&#34;video-container&#34;&gt;
&lt;iframe src=&#34;//player.vimeo.com/video/53221560&#34; width=&#34;500&#34; height=&#34;281&#34; frameborder=&#34;0&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt; &lt;p&gt;&lt;a href=&#34;http://vimeo.com/53221560&#34;&gt;Go: code that grows with grace&lt;/a&gt; from &lt;a href=&#34;http://vimeo.com/user4280938&#34;&gt;&amp;Oslash;redev Conference&lt;/a&gt; on &lt;a href=&#34;https://vimeo.com&#34;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Brendan Gregg, Linux Performance</title>
      <link>http://theb0ardside.com/brendangregglinuxperformance</link>
      <pubDate>Wed, 12 Jun 2013 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/brendangregglinuxperformance</guid>
      <description>&lt;p&gt;The always interesting Brendan Greg &amp;#8212; &lt;/p&gt;&lt;p&gt;&lt;iframe width=&#34;590&#34; height=&#34;332&#34; src=&#34;http://www.youtube.com/embed/0yyorhl6IjM?feature=oembed&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Berkshelf - the missing piece</title>
      <link>http://theb0ardside.com/berkshelfthemissingpiece</link>
      <pubDate>Wed, 29 May 2013 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/berkshelfthemissingpiece</guid>
      <description>&lt;p&gt;If you&#39;ve been following my past few posts, you&#39;ve seen i was investigating how best to integrate the plethora of Chef testing tools that&#39;ve been coming out &amp;#8212; foodcritic, chefspec, test-kitchen, mini-test &amp;#8212; and although not testing tools per se, Berkshelf and Vagrant are the other pieces of the puzzle&amp;#8230; but how to fit them all together? What is the directory structure for keeping your Berkfile - at the top of the repo? Inside a cookbook directory? How many Vagrant files am I going to create here?&lt;/p&gt;&lt;p&gt;If, like myself, you weren&#39;t along at this year&#39;s ChefConf 2013, you may also have missed on a major conceptual shift that has happened. Instead of the all-inclusive Chef-repo design pattern, as implied by the OpsCode Chef Repo - https://github.com/opscode/chef-repo - which, when used with all the community cookbooks out there, creates a mess of forked, modified and sub-moduled cookbooks and recipes. &lt;/p&gt;&lt;p&gt;The conceptual shift away and now recommended way, is to treat each cookbook as a separate piece of software and to give it it&#39;s own git repo, keeping them separate from from your Chef-repo. This combined, with a distinction between Library and Application cookbooks, and then bundled together via Berkshelf, enables a much cleaner and modular way of working. When you accept this move, it&#39;s much easier to then fit all the testing pieces together as they all live within each separate cookbook/repo.&lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/RiotGames/berkshelf/issues/535&#34; title=&#34;Berk Comment&#34; target=&#34;_blank&#34;&gt;This Comment Thread&lt;/a&gt; was what really drew it together for me, and then to fully clarify this way of working, watch Jamie Winsor&#39;s ChefConf talk which is the original starting point:&lt;/p&gt;&lt;p&gt;&lt;iframe width=&#34;590&#34; height=&#34;332&#34; src=&#34;http://www.youtube.com/embed/hYt0E84kYUI?feature=oembed&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mo&#39; Chef Testing</title>
      <link>http://theb0ardside.com/mocheftesting</link>
      <pubDate>Mon, 27 May 2013 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/mocheftesting</guid>
      <description>&lt;p&gt;Following on from my last post about Test Driven Chef, this latest Food Fight show is a great roundup of the current testing tools landscape -&lt;/p&gt;&lt;p&gt;&lt;iframe width=&#34;590&#34; height=&#34;332&#34; src=&#34;http://www.youtube.com/embed/DhcXXOIerIc?feature=oembed&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Test-Driven Chef</title>
      <link>http://theb0ardside.com/testdrivenchef</link>
      <pubDate>Wed, 15 May 2013 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/testdrivenchef</guid>
      <description>&lt;p&gt;I&#39;m looking to start using Test-Kitchen and Berkshelf, and basically trying to get my head round setting up a proper test driven Chef setup.&lt;/p&gt;&lt;p&gt;I found this video from last year to be quite a good introduction to some of the setup -&lt;/p&gt;&lt;p&gt;&lt;iframe width=&#34;590&#34; height=&#34;332&#34; src=&#34;http://www.youtube.com/embed/o2e0aZUAVGw?feature=oembed&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Netflix OSS</title>
      <link>http://theb0ardside.com/netflixoss</link>
      <pubDate>Sat, 11 May 2013 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/netflixoss</guid>
      <description>&lt;p&gt;Found this to be a particularly good episode of The Food Fight show with Jeremy Edberg and Adrian Cockcroft talking about the Netflix tools and architecture:&lt;/p&gt;&lt;p&gt;&lt;iframe width=&#34;590&#34; height=&#34;332&#34; src=&#34;http://www.youtube.com/embed/A69uTnfQgB8?feature=oembed&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Etsy Scaling vid from 2011</title>
      <link>http://theb0ardside.com/etsyscalingvidfrom2011</link>
      <pubDate>Thu, 17 Jan 2013 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/etsyscalingvidfrom2011</guid>
      <description>&lt;p&gt;&lt;iframe width=&#34;590&#34; height=&#34;332&#34; src=&#34;http://www.youtube.com/embed/eenrfm50mXw?feature=oembed&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;All well accepted practices by now, but still a good watch.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Usenix/Lisa 12</title>
      <link>http://theb0ardside.com/usenixlisa12</link>
      <pubDate>Sun, 16 Dec 2012 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/usenixlisa12</guid>
      <description>&lt;p&gt;Just got back from the Usenix/Lisa 12 conference in San Diego, and had a great time, super inspiring talks and content.&lt;/p&gt;&lt;p&gt;Highlight of the conference for me was Brendan Gregg speaking on Performance Analysis Methodologies - most of his talk was based upon a paper he just published in ACM - &lt;a href=&#34;https://queue.acm.org/detail.cfm?id=2413037&#34; title=&#34;ACM&#34; target=&#34;_blank&#34;&gt;Thinking Methodically About Performance&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The talks haven&#39;t yet been published on the Usenix website, but Brendan&#39;s blog has a ton of great looking content and older talks including this one on Visualisations for Performance Analysis&lt;/p&gt;&lt;p&gt;&lt;iframe width=&#34;590&#34; height=&#34;332&#34; src=&#34;http://www.youtube.com/embed/ml-t-9g6Mjc?fs=1&amp;#038;feature=oembed&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Percona Table Checksum</title>
      <link>http://theb0ardside.com/perconatablechecksum</link>
      <pubDate>Thu, 11 Oct 2012 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/perconatablechecksum</guid>
      <description>&lt;p&gt;&lt;iframe src=&#34;http://blip.tv/play/AYLoizwC.html?p=1&#34; width=&#34;550&#34; height=&#34;443&#34; scrolling=&#34;no&#34; class=&#34;iframe-class&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;&lt;p&gt;I must admit MySQL replication is something I&amp;rsquo;ve never felt too comfortable with - in most of my positions, I&amp;rsquo;ve had the luxury of working with a full time DBA who would handle all database related work. In my current workplace we have three major pairs of database machines, and have been going through upgrading them all to Percona MySQL 5.5. As you&amp;rsquo;d expect data integrity is of the highest importance, so discovering this Percona Table Checksum tool is a real life saver, providing an amazing tool for verifying and fixing any drift or problems with MySQL slaves.&lt;/p&gt;&lt;p&gt;I can&amp;rsquo;t take any credit for these instructions or the trial and error in assembling them, as they were penned by my workmate, the awesome &lt;a href=&#34;http://www.linkedin.com/pub/trystan-leftwich/12/19b/8a2&#34; target=&#34;_blank&#34;&gt;Trystan Leftwich&lt;/a&gt; - these are his notes for use at our place, with some additional clarifications from myself from working through them.&lt;/p&gt;&lt;p&gt;First things first, grab &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit&#34; title=&#34;PT&#34; target=&#34;_blank&#34;&gt;the Percona Toolkit&lt;/a&gt; and install.&lt;/p&gt;&lt;p&gt;Now on the master DB do the following:&lt;/p&gt;&lt;p&gt;&lt;code&gt;create database BLAH;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;This will be the database you store your checksums, so something like &lt;strong&gt;pt_checksums&lt;/strong&gt; will do.&lt;/p&gt;&lt;p&gt;Now on the master as the mysql user, run&lt;/p&gt;&lt;p&gt;&lt;code&gt;pt-table-checksum &amp;ndash;create-replicate &amp;ndash;replicate [db_name].[table_name] &amp;ndash;databases [comma_separated_list_of_databases_you_want_to_check] &amp;ndash;empty-replicate-table &amp;ndash;chunk-size=5000 localhost&lt;br /&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Where [db_name].[table_name] is the database you created before, and a table name you will be able to remember. &lt;/p&gt;&lt;p&gt;EG &lt;strong&gt;pt_checksums.myimportanttables_checksums&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;(If you get a &amp;#8220;can not connect to host: blah, this is ok, ignore)&lt;/p&gt;&lt;p&gt;Now, when this is complete, go to the slave DB. (ensure replication is up to date - if you have errors, just skip them to get it up to date)&lt;/p&gt;&lt;p&gt;Then run the following&lt;/p&gt;&lt;p&gt;&lt;code&gt;connect [db_you_created_above];&lt;br /&gt;select * from [table_name_you_created_above] where this_crc != master_crc;&lt;br /&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;If this returns an empty set, Then your DB is in sync - go straight to Go, collect $200. &lt;/p&gt;&lt;p&gt;If not you will have to try and sync it -&lt;/p&gt;&lt;p&gt;Create a user with the following permissions (pretty much everything)  (Also it may not need all of these, but couldn&amp;rsquo;t find what exactly it needed)&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;You can create with:&lt;/p&gt;&lt;p&gt;&lt;code&gt;create user &amp;#039;pt_checksum_maint&amp;#039;@&amp;#039;%&amp;#039; identified by &amp;#039;blah&amp;#039;;&lt;br /&gt;GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT on &lt;em&gt;.&lt;/em&gt; to  &amp;#039;pt_checksum_maint&amp;#039;@&amp;#039;%&amp;#039;;&lt;br /&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Then, still on the master, run the following command&lt;/p&gt;&lt;p&gt;&lt;code&gt;pt-table-sync &amp;ndash;execute &amp;ndash;replicate [db_name].[table_name] master_db_ip/hostname &amp;ndash;user user_you_created_above &amp;ndash;ask-pass &amp;ndash;no-foreign-key-checks&lt;br /&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;(At first I assumed this would be run on the slave to fix it up, however the man page for pt-table-checksum explains: &lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;it always makes the changes on the replication master, never the replication slave directly.  This is in general the only safe way to bring a replica back in sync with its master; changes to the replica are usually the source of the problems in the first place.  However, the changes it makes on the master should be no-op changes that set the data to their current values, and actually affect only the replica.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;)&lt;/p&gt;&lt;p&gt;Once this table sync has been run, re-run the pt-table-checksum command, then verify your results on the slave - should be good .&lt;/p&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>perl parp parp</title>
      <link>http://theb0ardside.com/perlparpparp</link>
      <pubDate>Sun, 02 Sep 2012 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/perlparpparp</guid>
      <description>&lt;p&gt;I updated the IP address for both my Name Servers tonite, and was monitoring to see how quickly the new addresses were propagating.  First stop was the exceptionally useful &lt;a href=&#34;http://www.whatsmydns.net/ &#34; title=&#34;What&amp;#039;s My DNS?&#34; target=&#34;_blank&#34;&gt;Whats My DNS&lt;/a&gt;&lt;/p&gt;&lt;p&gt;At the host level I also wanted to track the incoming DNS queries using tcpdump. I could see them streaming into the new host, and visually you could see an obvious difference when viewing the output of the same command on the old host. I googled around for a timer utility which run a command for a given time, so i could quantify the difference. Perfect answer was &lt;a href=&#34;http://stackoverflow.com/questions/601543/command-line-command-to-auto-kill-a-command-after-a-certain-amount-of-time&#34; title=&#34;Stack Overflow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, a simple perl wrapper function.&lt;/p&gt;&lt;p&gt;Here&#39;s how to use it to run tcpdump command for sixty seconds, and count the packets seen:&lt;/p&gt;&lt;p&gt;&lt;small&gt;&lt;code&gt;# doalarm () { perl -e &amp;#039;alarm shift; exec @ARGV&amp;#039; &#34;$@&#34;; }&lt;br /&gt;# doalarm 60 tcpdump -u  -i eth0 port 53  -n  |wc -l&lt;br /&gt;tcpdump: verbose output suppressed, use -v or -vv for full protocol decode&lt;br /&gt;listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes&lt;br /&gt;19504&lt;/code&gt;&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>tcpdump patterns</title>
      <link>http://theb0ardside.com/tcpdumppatterns</link>
      <pubDate>Fri, 29 Jun 2012 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/tcpdumppatterns</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7185/6844034348_50dd1c5f32_b.jpg&#34; alt=&#34;McCarthy&#34; /&gt;&lt;/p&gt;&lt;p&gt;I use tcpdump a lot, but mostly at a reasonably high level, only really restricting the capture to host and port info, then pulling the dump back into Wireshark for nicer visualisation and easier filtering.&lt;/p&gt;&lt;p&gt;A couple of months back I read &lt;a href=&#34;http://www.amazon.com/Moonwalking-Einstein-Science-Remembering-Everything/dp/159420229X&#34; title=&#34;Moonwalking With Einstein&#34; target=&#34;_blank&#34;&gt;Moonwalking With Einsten&lt;/a&gt;, which is a nice pop-science history of the importance of memory in previous societies, alongside the contemporary phenomena of &lt;a href=&#34;http://www.worldmemorychampionships.com/&#34; title=&#34;World Memory Competitions&#34; target=&#34;_blank&#34;&gt;competitive memory competitions&lt;/a&gt;. The book is great, and explains how feats of memory are achieved via the technique of &lt;a href=&#34;http://en.wikipedia.org/wiki/Method_of_loci&#34; title=&#34;Memory Palaces&#34; target=&#34;_blank&#34;&gt;memory palaces&lt;/a&gt;, a technique dating back to Roman times - spatial memory relationships. I&#39;ve been using the technique a lot since I read this book, and truly, no magic to it, it really works. Basically, when you have a list of items to remember, you weave each item, in order, into a spatially focussed narrative.&lt;/p&gt;&lt;p&gt;So, last night, I get out my copy of TCP/IP Illustrated, Volume 1*, one of my most-returned-to tech books - I&#39;ve always wanted to have a more encyclopedic knowledge of the lower level details of TCP/IP, and last night applied the Memory Palace Technique to the structure of a TCP packet.&lt;br/&gt;
(( read the &lt;a href=&#34;http://en.wikipedia.org/wiki/Method_of_loci&#34; title=&#34;Memory Palace - Wikipedia&#34; target=&#34;_blank&#34;&gt;wikipedia article&lt;/a&gt; for more details)) &lt;/p&gt;
&lt;p&gt;In my memory palace I was walking down the path towards the house where I grew up, and seeing a &amp;#8216;&lt;strong&gt;S&lt;/strong&gt;o&lt;strong&gt;RC&lt;/strong&gt;erer/&lt;strong&gt;Src Port&lt;/strong&gt;&amp;#8216; battling with &amp;#8216;Dick &lt;strong&gt;D&lt;/strong&gt;a&lt;strong&gt;ST&lt;/strong&gt;ardly and Mutley/&lt;strong&gt;Dst Port&lt;/strong&gt;&amp;#8216;, then walk into my mothers front hallway with a &lt;strong&gt;Sequence Number&lt;/strong&gt; along the front hall, then my Grandfather sitting in a chair in the living room saying &amp;#8220;&lt;strong&gt;ACK&lt;/strong&gt;!&amp;#8221; because the soccer is on the television and he&#39;s complaining about the &lt;strong&gt;Header Length&lt;/strong&gt; &amp;#8230; you get the idea - but yeah, you need to make your own memory palace.&lt;/p&gt;&lt;p&gt;Now that I have a complete image of this TCP packet in my head suddenly expressions like :&lt;/p&gt;&lt;p&gt;&lt;code&gt;tcpdump -ni en1 tcp[13] == 18 and host 172.16.1.200 and port 80 &lt;/code&gt;&lt;/p&gt;&lt;p&gt;are way easier to understand and use - the &lt;code&gt;tcp[13]&lt;/code&gt; part refers to the 13th Octet of the packet, which is the Flags octet, then the &lt;code&gt;18&lt;/code&gt; part is a simple decimal representation of the binary flags, in the order they are in the diagram above - i.e the Flags are &lt;/p&gt;&lt;p&gt;&lt;code&gt;CWR | ECE | URG | ACK | PSH | RST | SYN | FIN&lt;/code&gt; &lt;/p&gt;&lt;p&gt;so in my example 18 refers to having both the ACK and SYN flags set - 00010010 which if you&#39;re used to dealing with netmasks math is quite an easy translation. My example, then, will only capture the first response packet from the server, as it would be the only part of the conversation to have both an ACK and SYN flag set. (I used a separate memory palace for the flags themselves)&lt;/p&gt;&lt;p&gt;To capture all SYN packets, including the ACK/SYN ones, you would use:&lt;/p&gt;&lt;p&gt;&lt;code&gt;tcpdump -ni en1 &amp;#039;tcp[13] == 18 or tcp[13] == 2&amp;#039; and host 172.16.1.200 and port 80&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Memory Palaces are pretty damn useful!&lt;/p&gt;&lt;p&gt;** Most Engineers are aware of TCP/IP Illustrated, however a lot of people I&#39;ve spoken to aren&#39;t aware there was a &lt;a href=&#34;http://www.amazon.com/TCP-Illustrated-Volume-Addison-Wesley-Professional/dp/0321336313/ref=pd_sim_b_1&#34; title=&#34;TCP/IP Illustrated Vol 1 Edition 2&#34; target=&#34;_blank&#34;&gt;2nd Edition published in November of 2011, updated by a guy named Kevin R. Fall&lt;/a&gt; - I would absolutely recommend it, an amazing book and especially with the updates, just seems an essential addition to any Engineer&#39;s library..&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Puppet stages and APT</title>
      <link>http://theb0ardside.com/puppetstagesandapt</link>
      <pubDate>Tue, 03 Apr 2012 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/puppetstagesandapt</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://www.stixrideshop.com/blog/wp-content/uploads/2012/03/gonz-3.bmp&#34; alt=&#34;gonz -- for no reason except he&amp;#039;s the MAN!&#34; /&gt;&lt;/p&gt;&lt;p&gt;At work, our old code deployment strategy was basically a wrapper script doing an svn checkout and some symlinking. With our move to Puppet for config management, we also moved to using Apt packaging for our code deployment, tying them together with a line similar to :&lt;/p&gt;&lt;p&gt;&lt;code&gt;class foo-export {&lt;br /&gt;    package { &amp;#039;foo-export&amp;#039;: ensure =&gt; latest }&lt;br /&gt;}&lt;/code&gt;&lt;/p&gt;&lt;p&gt;So that whenever we deploy a new version of a package to our apt-repo, it can then be installed with a:&lt;/p&gt;&lt;p&gt;&lt;code&gt;puppet agent --test&lt;/code&gt;&lt;br /&gt;(and with an initial dry-run using &lt;code&gt;--noop&lt;/code&gt;)&lt;/p&gt;&lt;p&gt;( I should mention I manage our Puppet runs via our own distributed scripts, rather than having the nodes set up to check in every 30mins - when I&#39;m doing so much work on our Puppet setup and config, I&#39;d rather not having machines check in automatically in case the config is in a broken state )&lt;/p&gt;&lt;p&gt;Inevitably I would run the above Puppet command and it would not find any new packages, because &amp;#8216;d&#39;uh!&#39;, of course I still need to run an &lt;code&gt;apt-get update&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;I&#39;ve been using Puppet stages for a while now, in order to group package installations in a broader sense rather than manually spelling out every dependency with a &lt;code&gt;require =&gt;&lt;/code&gt; stanza, so it was a simple addition to add in a &lt;code&gt;pre&lt;/code&gt; stage, and have the nodes run &lt;code&gt;apt-get update&lt;/code&gt; before any runs.&lt;/p&gt;&lt;p&gt;In order to use stages, you need to first define them in your site.pp. By default every defined class runs under Stage[main], so you just need to add the new stages and define the running order. (full Puppet stage documentation is &lt;a href=&#34;http://docs.puppetlabs.com/guides/language_guide.html&#34; title=&#34;Puppet Stages&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;&lt;p&gt;At the top of my site.pp file, I added a pre and post stage, then define the execution order via:&lt;/p&gt;&lt;p&gt;&lt;code&gt;stage { [pre, post]: }&lt;br /&gt;Stage[pre] -&gt; Stage[main] -&gt; Stage[post]&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Then I created a class called apt-hupdate (sorry, i use stupid naming conventions!) in&lt;br /&gt;&lt;code&gt;modules/apt-hupdate/manifests/init.pp&lt;/code&gt;&lt;/p&gt;&lt;p&gt;which contained:&lt;br /&gt;&lt;code&gt;class apt-hupdate {&lt;/p&gt;&lt;p&gt;    exec { &#34;aptHupdate&#34;:&lt;br /&gt;        command =&gt; &#34;/usr/bin/apt-get update&#34;,&lt;br /&gt;    }&lt;br /&gt;}&lt;/code&gt;&lt;/p&gt;&lt;p&gt;And finally, include that in your site.pp with:&lt;/p&gt;&lt;p&gt;&lt;code&gt;class { apt-hupdate: stage =&gt; pre }&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Now every time you do a Puppet run, &lt;code&gt;apt-get update&lt;/code&gt; will be the first task run.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vagrant and Chef setup</title>
      <link>http://theb0ardside.com/vagrantandchefsetup</link>
      <pubDate>Fri, 05 Aug 2011 00:00:00 UTC</pubDate>
      <author>Thorsten Sideb0ard</author>
      <guid>http://theb0ardside.com/vagrantandchefsetup</guid>
      <description>&lt;p&gt;I&#39;ve been reading through ThoughtWorks&#39; latest &amp;#8216;&lt;a href=&#34;http://www.thoughtworks.com/radar&#34; title=&#34;radar&#34; target=&#34;_blank&#34;&gt;technology radar&lt;/a&gt;&amp;#8216; which led me to look up &lt;a href=&#34;http://vagrantup.com/&#34; title=&#34;Vagrant&#34; target=&#34;_blank&#34;&gt;Vagrant&lt;/a&gt;, one of the tools they list as worth exploring.&lt;/p&gt;&lt;p&gt;Vagrant is a framework for building and deploying Virtual Machine environments, using Oracle VirtualBox for the actual VMs and utilizing Chef for configuration management.  &lt;/p&gt;&lt;p&gt;Watching through this intro video:&lt;/p&gt;&lt;p&gt;http://vimeo.com/9976342&lt;/p&gt;&lt;p&gt;i was quite intrigued as it is very similar to what i was looking to achieve earlier when i was &lt;a href=&#34;http://www.theb0ardside.com/?p=22&#34; title=&#34;Xen and Puppet&#34; target=&#34;_blank&#34;&gt;experimenting with installing Xen and configuring with Puppet.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;So here&#39;s what I experienced during the setup of Vagrant on my Macbook - I decided to start with a simple Chef install to familiarise myself with Chef itself and it&#39;s own requirements CouchDB, RabbitMQ and Solr, mostly by following &lt;a href=&#34;http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration&#34; title=&#34;Chef Manual Install OS X&#34; target=&#34;_blank&#34;&gt;these instructions&lt;/a&gt; - &lt;/p&gt;&lt;p&gt;&lt;strong&gt;-CHEF INSTALL-&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;sudo gem install chef&lt;br /&gt;sudo gem install ohai&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Chef uses couchDB as it&#39;s datastore, so we need to install it using the instructions &lt;a href=&#34;http://wiki.apache.org/couchdb/Installing_on_OSX&#34; title=&#34;CouchDB install OS X&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; &lt;/p&gt;&lt;p&gt;&lt;strong&gt;brew install couchdb&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The instructions I list above also contains steps to install a couchDB user and set it up as a daemon. They didn&#39;t work for me, and after 30mins of troubleshooting, i gave up and went with the simpler option of running it under my own user - in production this will be running on a Linux server rather than my Macbook, so it seemed fair enough -&lt;/p&gt;&lt;p&gt;&lt;strong&gt;cp /usr/local/Cellar/couchdb/1.1.0/Library/LaunchDaemons/org.apache.couchdb.plist ~/Library/LaunchAgents/&lt;/p&gt;&lt;p&gt;launchctl load -w ~/Library/LaunchAgents/org.apache.couchdb.plist&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Check its running okay by going to&lt;br /&gt;&lt;a href=&#34;http://127.0.0.1:5984/&#34; title=&#34;Localhost&#34; target=&#34;_blank&#34;&gt;http://127.0.0.1:5984/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;which should provide something akin to :&lt;br /&gt;&lt;strong&gt;{&amp;#8220;couchdb&amp;#8221;:&amp;#8221;Welcome&amp;#8221;,&amp;#8221;version&amp;#8221;:&amp;#8221;1.1.0&amp;#8243;}&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;- INSTALL RABBITMQ -&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;brew install rabbitmq&lt;br /&gt;/usr/local/sbin/rabbitmq-server -detached&lt;/p&gt;&lt;p&gt;sudo rabbitmqctl add_vhost /chef&lt;br /&gt;sudo rabbitmqctl add_user chef testing&lt;br /&gt;sudo rabbitmqctl set_permissions -p /chef chef &amp;#8220;.*&amp;#8221; &amp;#8220;.*&amp;#8221; &amp;#8220;.*&amp;#8221;&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ok, Gettin&#39; back to my mission, break out the whipped cream and the cherries, then I go through all the fly positions - oh, wrong mission! &lt;/p&gt;&lt;p&gt;Ok..&lt;/p&gt;&lt;p&gt;&lt;strong&gt;brew install gecode&lt;br /&gt;brew install solr&lt;/p&gt;&lt;p&gt;sudo gem install chef-server chef-server-api chef-server chef-solr&lt;br /&gt;sudo gem install chef-server-webui&lt;br /&gt;sudo chef-solr-installer&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Setup a conf file -&lt;br /&gt;&lt;strong&gt;sudo mkdir /etc/chef&lt;br /&gt;sudo vi /etc/chef/server.rb&lt;/strong&gt; - paste in the example from:&lt;/p&gt;&lt;p&gt;&lt;a href=&#34;http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration&#34; title=&#34;chef conf&#34; target=&#34;_blank&#34;&gt;http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration&lt;/a&gt; - making the appropriate changes for your FQDN&lt;/p&gt;&lt;p&gt;At this point, the above instructions ask you to start the indexer however the instructions haven&#39;t been updated to reflect changes to Chef version 0.10.2 in which chef-solr-indexer has been replaced with chef-expander&lt;/p&gt;&lt;p&gt;So, instead of running:&lt;br /&gt;&lt;strong&gt;sudo chef-solr-indexer &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;you instead need to run:&lt;br /&gt;&lt;strong&gt;sudo chef-expander -n1 -d&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Next i tried&lt;br /&gt;&lt;strong&gt;sudo chef-solr&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;which ran into&lt;br /&gt;&lt;em&gt;&amp;#8220;`configure_chef&#39;: uninitialized constant Chef::Application::SocketError (NameError)&amp;#8221;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;i had to create an &lt;strong&gt;/etc/chef/solr.rb&lt;/strong&gt; file and simply add this to the file:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;require &amp;#8216;socket&#39;&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;startup now worked -&lt;br /&gt;if you want to daemonize it, use:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;sudo chef-solr -d&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Next start Chef Server with:&lt;br /&gt;&lt;strong&gt;sudo chef-server -N -e production -d&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;and finally:&lt;br /&gt;&lt;strong&gt;sudo chef-server-webui -p 4040 -e production&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Now you should be up and running - you need to configure the command client &amp;#8216;Knife&#39; follwing the instructions &lt;a href=&#34;http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration&#34; title=&#34;Knife setup&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; - under the section &amp;#8216;&lt;strong&gt;Configure the Command Line Client&lt;/strong&gt;&amp;#8216;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;mkdir -p ~/.chef&lt;br /&gt;sudo cp /etc/chef/validation.pem /etc/chef/webui.pem ~/.chef&lt;br /&gt;sudo chown -R $USER ~/.chef&lt;/p&gt;&lt;p&gt;knife configure -i&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;(follow the instructions at the link - you only need to change the location of the two pem files you copied above)&lt;/p&gt;&lt;p&gt;Ok, so hopefully you&#39;re at the same place as me with this all working at least as far as being able to log into CouchDB, and verifying that Chef/Knife are both working.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;- VAGRANT SETUP -&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Now, onward with the original task of Vagrant setup&amp;#8230;&lt;br /&gt;Have a read over the &lt;a href=&#34;http://vagrantup.com/docs/getting-started/index.html &#34; title=&#34;Vagrant Getting Started&#34; target=&#34;_blank&#34;&gt;getting started guide:&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Install VirtualBox - download from &lt;a href=&#34;http://www.virtualbox.org/wiki/Downloads&#34; title=&#34;VirtualBox&#34; target=&#34;_blank&#34;&gt;http://www.virtualbox.org/wiki/Downloads&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Run the installer, which should all work quite easily. Next..&lt;/p&gt;&lt;p&gt;&lt;strong&gt;gem install vagrant&lt;/p&gt;&lt;p&gt;mkdir vagrant_guide&lt;br /&gt;cd vagrant_guide/&lt;br /&gt;vagrant init&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;this creates the base Vagrantfile, which the documentation compares to a Makefile, basically a reference file for the project to work with.&lt;/p&gt;&lt;p&gt;Setup our first VM -&lt;br /&gt;&lt;strong&gt;vagrant box add lucid32 http://files.vagrantup.com/lucid32.box&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This is downloaded and saved in ~/.vagrant.d/boxes/ &lt;/p&gt;&lt;p&gt;edit the Vagrantfile which was created and change the &amp;#8220;box&amp;#8221; entry to be &amp;#8220;lucid32&amp;#8243;, the name of the file we just saved. &lt;/p&gt;&lt;p&gt;Bring it online with:&lt;br /&gt;&lt;strong&gt;vagrant up&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;then ssh into with&lt;br /&gt;&lt;strong&gt;vargrant ssh&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ace, that worked quite easily. After a little digging around, I  logged out and tore the machine down again with&lt;br /&gt;&lt;strong&gt;vagrant destroy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;- TYING IT ALL TOGETHER -&lt;/strong&gt;&lt;br /&gt;Now we need to connect our Vagrant install with our Chef server&lt;/p&gt;&lt;p&gt;First, clone the Chef repository with:&lt;br /&gt;&lt;strong&gt;git clone git://github.com/opscode/chef-repo.git &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;add this dir to your &lt;strong&gt;~/.chef/knife.rb&lt;/strong&gt; file&lt;br /&gt;i.e&lt;br /&gt;&lt;strong&gt;cookbook_path           [&#34;/Users/thorstensideboard/chef-repo/cookbooks&#34;]&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Download the Vagrant cookbook they use in their examples -&lt;/p&gt;&lt;p&gt;&lt;strong&gt;wget http://files.vagrantup.com/getting_started/cookbooks.tar.gz&lt;br /&gt;tar xzvf cookbooks.tar.gz&lt;br /&gt;mv cookbooks/* chef-repo/cookbooks/&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Add it to our Chef server using Knife:&lt;br /&gt;&lt;strong&gt;knife cookbook upload -a&lt;/strong&gt;&lt;br /&gt;(knife uses the cookbook_path we setup above)&lt;/p&gt;&lt;p&gt;If you browse to your localhost at&lt;br /&gt;&lt;strong&gt;http://sbd-ioda.local:4040/cookbooks/&lt;/strong&gt;&lt;br /&gt;you should see the three new cookbooks which have been added.&lt;/p&gt;&lt;p&gt;Now to edit Vagrantfile and add your Chef details:&lt;br /&gt;&lt;code&gt;&lt;br /&gt;Vagrant::Config.run do |config|&lt;/p&gt;&lt;p&gt;    config.vm.box = &#34;lucid32&#34;&lt;/p&gt;&lt;p&gt;    config.vm.provision :chef_client do |chef|&lt;/p&gt;&lt;p&gt;    chef.chef_server_url = &#34;http://SBD-IODA.local:4000&#34;&lt;br /&gt;    chef.validation_key_path = &#34;/Users/thorsten/.chef/validation.pem&#34;&lt;br /&gt;    chef.add_recipe(&#34;vagrant_main&#34;)&lt;br /&gt;    chef.add_recipe(&#34;apt&#34;)&lt;br /&gt;    chef.add_recipe(&#34;apache2&#34;)&lt;/p&gt;&lt;p&gt;    end&lt;br /&gt;end&lt;br /&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;I tried to load this up with&lt;br /&gt;&lt;strong&gt;vagrant up&lt;/strong&gt;&lt;br /&gt;however received:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&amp;#8220;[default] [Fri, 05 Aug 2011 09:27:07 -0700] INFO: *** Chef 0.10.2 ***&lt;br /&gt;: stdout&lt;br /&gt;[default] [Fri, 05 Aug 2011 09:27:07 -0700] INFO: Client key /etc/chef/client.pem is not present - registering&lt;br /&gt;: stdout&lt;br /&gt;[default] [Fri, 05 Aug 2011 09:27:28 -0700] FATAL: Stacktrace dumped to /srv/chef/file_store/chef-stacktrace.out&lt;br /&gt;: stdout&lt;br /&gt;[default] [Fri, 05 Aug 2011 09:27:28 -0700] FATAL: SocketError: Error connecting to http://SBD-IODA.local:4000/clients - getaddrinfo: Name or service not known&amp;#8221;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;I figured this was a networking issue, and yeah, within the VM it has no idea of my Macbook&#39;s local hostname, which i fixed by editing its /etc/hosts file and manually adding it.&lt;/p&gt;&lt;p&gt;Upon issuing a&lt;br /&gt;&lt;strong&gt;vagrant reload&lt;/strong&gt;, boom! you can see the Vagrant host following the recipes and loading up a bunch of things including apache2&lt;/p&gt;&lt;p&gt;However at this point, you can still only access it&#39;s webserver from within the VM, so in order to access it from our own desktop browser, we can add the following line to the Vagrantfile:&lt;br /&gt;&lt;strong&gt;config.vm.forward_port(&amp;#8220;web&amp;#8221;, 80, 8080)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;After another reload, you should now be able to connect to localhost:8080 and access your new VM&#39;s apache host.&lt;/p&gt;&lt;p&gt;In order to use this setup in any sort of dev environment will still need a good deal more work, but for the moment, this should be enough to get you up and running and able to explore both Vagrant and Chef. &lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
