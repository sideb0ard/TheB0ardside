<!DOCTYPE html>
<html class="no-js" lang="en-US" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#">
<head>
    <meta charset="utf-8">

    <base href="http://theb0ardside.com">
    <title> TheB0ardside.com </title>
    <link rel="canonical" href="http://theb0ardside.com/tags/configuration-management.html">
    <link href="http://theb0ardside.com/static/css/b0ardstrap.min.css" rel="stylesheet"/>
    <link href="http://theb0ardside.com/static/css/b0ardstyle.css" rel="stylesheet"/>

    <link rel="alternate" type="application/rss+xml" title="RSS" href="http://theb0ardside.com/index.xml" />

</head>
<body lang="en">
<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  
  <div class="navbar-blah">
  <div class="navbar-header">
    <a class="navbar-brand" href="http://theb0ardside.com/">The B0ardside_</a>
  </div>

  <div>
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">hello<b class="caret"></b></a>
        <ul class="dropdown-menu">
            <li><img src="http://theb0ardside.com/static/img/thor.jpg"></li>
            <li><a target="new" href="http://theb0ardside.com/categories/blog/">All Articles</a></li>
            <li><a target="new" href="mailto:thorsten@theb0ardside.com?subject=hullo">Email</a></li>
            <li><a target="new" href="http://github.com/sideb0ard">Code</a></li>
            <li><a target="new" href="http://drawingb0ard.blogspot.com/">Drawings</a></li>
            <li><a target="new" href="http://bff.fm/shows/the-nodecast">Radio Show</a></li>
            <li><a target="new" href="https://sideb0ard.bandcamp.com/">Music</a></li>
            <li><a target="new" href="http://twitter.com/sideb0ard">Twitter</a></li>
            <li><a target="new" href="http://theb0ardside.com/index.xml">Rss Feed</a></li>
        </ul>
      </li>
    </ul>
  </div>
</div>
</nav>

  <div class="container">
  <div id="page">


<section id="main">
  <div>
   <h1 id="title">Configuration-Management</h1>
    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/berkshelfthemissingpiece/'> Berkshelf - the missing piece</a> </h2>
      <div class="post-meta">Wed, May 29, 2013</div>
    </header>
    <p>If you've been following my past few posts, you've seen i was investigating how best to integrate the plethora of Chef testing tools that've been coming out &#8212; foodcritic, chefspec, test-kitchen, mini-test &#8212; and although not testing tools per se, Berkshelf and Vagrant are the other pieces of the puzzle&#8230; but how to fit them all together? What is the directory structure for keeping your Berkfile - at the top of the repo? Inside a cookbook directory? How many Vagrant files am I going to create here?</p><p>If, like myself, you weren't along at this year's ChefConf 2013, you may also have missed on a major conceptual shift that has happened. Instead of the all-inclusive Chef-repo design pattern, as implied by the OpsCode Chef Repo - https://github.com/opscode/chef-repo - which, when used with all the community cookbooks out there, creates a mess of forked, modified and sub-moduled cookbooks and recipes. </p><p>The conceptual shift away and now recommended way, is to treat each cookbook as a separate piece of software and to give it it's own git repo, keeping them separate from from your Chef-repo. This combined, with a distinction between Library and Application cookbooks, and then bundled together via Berkshelf, enables a much cleaner and modular way of working. When you accept this move, it's much easier to then fit all the testing pieces together as they all live within each separate cookbook/repo.</p><p><a href="https://github.com/RiotGames/berkshelf/issues/535" title="Berk Comment" target="_blank">This Comment Thread</a> was what really drew it together for me, and then to fully clarify this way of working, watch Jamie Winsor's ChefConf talk which is the original starting point:</p><p><iframe width="590" height="332" src="http://www.youtube.com/embed/hYt0E84kYUI?feature=oembed" frameborder="0" allowfullscreen></iframe></p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/foodfightshowonchefcookbookbestpractises/'> Food Fight Show on Chef Cookbook Best Practises</a> </h2>
      <div class="post-meta">Mon, Nov 26, 2012</div>
    </header>
    <p><iframe width="590" height="332" src="http://www.youtube.com/embed/slF72K03ixM?fs=1&#038;feature=oembed" frameborder="0" allowfullscreen></iframe></p><p>this google+ hangout, combined with this <a href="http://devopsanywhere.blogspot.it/2012/11/how-to-write-reusable-chef-cookbooks.html" title="Reusable Chef Cookbooks" target="_blank">post</a> and all it's links, provides plenty of good discussion and ideas for Chef.</p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/cheflessonsfrometsy/'> Chef Lessons from Etsy</a> </h2>
      <div class="post-meta">Sun, Aug 5, 2012</div>
    </header>
    <p>really good video from this year's ChefConf::</p><p><iframe width="590" height="332" src="http://www.youtube.com/embed/nSnJCJiZDDU?fs=1&#038;feature=oembed" frameborder="0" allowfullscreen></iframe></p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/scalingatdropbox/'> scaling at dropbox</a> </h2>
      <div class="post-meta">Mon, Jul 16, 2012</div>
    </header>
    <p>I highly recommend this <a href="http://devopsweekly.com/" title="DevOps Weekly" target="_blank">DevOps Weekly mail out</a>. </p><p><img alt="" src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRiJpAEM" title="DevOps Weekly" class="aligncenter" width="798" height="362" /></p><p>The latest one has a bunch of good links, and one i found especially was this &#8220;<a href="http://eranki.tumblr.com/post/27076431887/scaling-lessons-learned-at-dropbox-part-1" title="Scaling at Dropbox" target="_blank">Scaling lessons learned at Dropbox, part 1</a>&#8220;.</p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/somefavvelocitytalks/'> some fav Velocity talks</a> </h2>
      <div class="post-meta">Mon, Jul 2, 2012</div>
    </header>
    <p><a href="http://velocityconf.com/velocity2012" title="Velocity" target="_blank">Velocity</a> was on last week, and I was following along enviously on twitter - I'm making a promise to myself that I'll be along in person next year!</p><p>Quite a few of the talks now appearing online - here's a couple I've watched so far..</p><p><iframe width="590" height="332" src="http://www.youtube.com/embed/2S0k12uZR14?fs=1&#038;feature=oembed" frameborder="0" allowfullscreen></iframe></p><p><iframe width="590" height="332" src="http://www.youtube.com/embed/bM0yL0eQ9EM?fs=1&#038;feature=oembed" frameborder="0" allowfullscreen></iframe></p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/puppetstagesandapt/'> Puppet stages and APT</a> </h2>
      <div class="post-meta">Tue, Apr 3, 2012</div>
    </header>
    <p><img src="http://www.stixrideshop.com/blog/wp-content/uploads/2012/03/gonz-3.bmp" alt="gonz -- for no reason except he&#039;s the MAN!" /></p><p>At work, our old code deployment strategy was basically a wrapper script doing an svn checkout and some symlinking. With our move to Puppet for config management, we also moved to using Apt packaging for our code deployment, tying them together with a line similar to :</p><p><code>class foo-export {<br />    package { &#039;foo-export&#039;: ensure => latest }<br />}</code></p><p>So that whenever we deploy a new version of a package to our apt-repo, it can then be installed with a:</p><p><code>puppet agent --test</code><br />(and with an initial dry-run using <code>--noop</code>)</p><p>( I should mention I manage our Puppet runs via our own distributed scripts, rather than having the nodes set up to check in every 30mins - when I'm doing so much work on our Puppet setup and config, I'd rather not having machines check in automatically in case the config is in a broken state )</p><p>Inevitably I would run the above Puppet command and it would not find any new packages, because &#8216;d'uh!', of course I still need to run an <code>apt-get update</code>.</p><p>I've been using Puppet stages for a while now, in order to group package installations in a broader sense rather than manually spelling out every dependency with a <code>require =></code> stanza, so it was a simple addition to add in a <code>pre</code> stage, and have the nodes run <code>apt-get update</code> before any runs.</p><p>In order to use stages, you need to first define them in your site.pp. By default every defined class runs under Stage[main], so you just need to add the new stages and define the running order. (full Puppet stage documentation is <a href="http://docs.puppetlabs.com/guides/language_guide.html" title="Puppet Stages" target="_blank">here</a>)</p><p>At the top of my site.pp file, I added a pre and post stage, then define the execution order via:</p><p><code>stage { [pre, post]: }<br />Stage[pre] -> Stage[main] -> Stage[post]</code></p><p>Then I created a class called apt-hupdate (sorry, i use stupid naming conventions!) in<br /><code>modules/apt-hupdate/manifests/init.pp</code></p><p>which contained:<br /><code>class apt-hupdate {</p><p>    exec { "aptHupdate":<br />        command => "/usr/bin/apt-get update",<br />    }<br />}</code></p><p>And finally, include that in your site.pp with:</p><p><code>class { apt-hupdate: stage => pre }</code></p><p>Now every time you do a Puppet run, <code>apt-get update</code> will be the first task run.</p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/buildingadebpackagefromaperlscript/'> building a DEB package from a perl script</a> </h2>
      <div class="post-meta">Thu, Feb 16, 2012</div>
    </header>
    <p>I have a speedtest perl script i wrote - nothing complicated, takes a file and uploads it to a remote FTP or SFTP server, while calculating how long, then gives you a a measure of the MB/per second bandwidth between two sites.</p><p>I want it available on a selection of machines so it can run from wherever, so I thought i'd package it up as a .DEB file and stick it in our local repo. Nothing complicated in that, and there are a <a href="http://www.debian-administration.org/articles/336" target="_blank">number</a> of <a href="http://www.debian-administration.org/articles/337" target="_blank">online</a> <a href="http://www.debian.org/doc/manuals/debian-faq/ch-pkg_basics.en.html" target="_blank">tutorials</a> about building your own debs. The main drawback with most I found was that they assume you are actually building from source rather than just distributing a script, although I also found <a href="http://askubuntu.com/questions/27715/create-a-deb-package-from-scripts-or-binaries" target="_blank">a relevant Ubuntu thread</a> which is pretty simple and to the point.</p><p>However, even using these tutorials it still took me a few hours to figure out. There are just a couple of non-obvious points, so i figure writing out my own steps is worth recording -</p><p>So first, grab your required packages:</p><p><strong><code>apt-get install dh-make dpkg-dev debhelper devscripts fakeroot lintian</code></strong></p><p>You will need to build from a directory with the name of your script in the form <code>packagename-version</code>, so for mine i created <strong>/tmp/speedtest-1.0</strong>, then copied in my script &#8216;<strong>speedtest</strong>&#8216; and it's data file <strong>25MBFLAC.file</strong> ( which i could have created with <strong>dd</strong> on the box rather than copy over, but downloading the file is actually quicker in this situation ).</p><p>The first step is to run:</p><p><strong><code>dh_make -s --indep --createorig -e thor@valhalla.com</code></strong><br />(dash-s means create a single binary .deb - i.e. no source version; indep means architecture-independent; and createorig is to indicate you are the original maintainer)</p><p>this creates a top-level &#8216;<strong>debian</strong>&#8216; directory containing all the necessary config files.<br />The main one you need to edit is <strong>debian/control</strong> - you prob only need fill in &#8220;section&#8221;, &#8220;homepage&#8221; and &#8220;Description&#8221;</p><p>Mine looks like:</p><p><code>Source: speedtest<br />Section: web<br />Priority: extra<br />Maintainer: Thorsten Sideboard &lt;thor@valhalla.com&gt;<br />Build-Depends: debhelper (>= 7.0.50~)<br />Standards-Version: 3.8.4<br />Homepage: http://github.com/sideboard/speedtest.git</p><p>Package: speedtest<br />Architecture: all<br />Depends: ${misc:Depends}<br />Description: Test Upload Speeds<br /></code></p><p>One of the things which baffled me for a while, which was answered in the <a href="http://askubuntu.com/questions/27715/create-a-deb-package-from-scripts-or-binaries" target="_blank">askubuntu link above</a>, was how to specify where something is installed &#8212; it goes in a file &#8216;<strong>debian/install</strong>&#8216; which isn't created for you. The format of the file is &#8216;<strong>filename location/to/be/installed</strong>&#8221; (without the initial slash)</p><p>so in my case, i ran:<br /><code>echo "speedtest usr/local/Scriptz/" > debian/install<br />echo "25MBFLAC.file usr/local/Scriptz/" >> debian/install<br /></code></p><p>At this point, you should then be able to run:<br /><code>debuild -us -uc</code></p><p>and you <em>should</em> have a deb file built. but..</p><p>First i ran into :</p><p><code>dpkg-source: error: can&#039;t build with source format &#039;3.0 (quilt)&#039;: no orig.tar file found</code></p><p>As the above-mentioned askubuntu post says, you can </p><p><code>echo "1.0" > debian/source/format</code></p><p>then re-running the <code>debuild -us -uc</code> i ran into </p><p><code>dpkg-source: error: cannot represent change to speedtemp-1.0/25MBFLAC.file: binary file contents changed</code></p><p>This error is due to leftover build-cruft from my last run - if you check the directory one step up from where you are, you'll see debuild has already built some files for you, typically a tar.gz, a .dsc and a .build file. Delete all them, then re-run <code>debuild -us -uc</code> &#8212; now it should build properly!</p><p>ah! </p><p><code>dh_usrlocal: debian/speedtemp/usr/local/Scriptz/speedtest is not a directory</code></p><p>This one also caught me out for a while - turns out this is caused by my specifying &#8220;/usr/local/Scriptz&#8221; as my install location - </p><blockquote><p>Most third-party software installs itself in the /usr/local directory hierarchy. On Debian this is reserved for private use by the system administrator, so packages must not use directories such as /usr/local/bin but should instead use system directories such as /usr/bin, obeying the Filesystem Hierarchy Standard (FHS).</p></blockquote><p> (from <a href="http://www.debian.org/doc/manuals/maint-guide/modify.en.html#destdir" target="_blank">here</a>)</p><p>So, yeah, i changed my <strong>debian/install</strong> file to be &#8220;<strong>speedtest usr/bin</strong>&#8221;</p><p>and finally! running <code>debuild -us -uc</code> completes properly, outputting a <strong>/tmp/speedtest_1.0-1_all.deb</strong> which can then be installed via<br /><strong><code>dpkg -i /tmp/speedtest_1.0-1_all.deb </code></strong></p><p>One last note &#8212; there are four useful scripts to also know about &#8212; <strong><code>preinst, postinst, prerm, postrm</code></strong> &#8212; these should be in the <code>debian/</code> directory - pretty self-explanatory - pre- and post- install and remove scripts - if these exist, they will be run exactly as they are named, so for example, i wanted my 25MBFLAC.file still to be installed under /usr/local/Scriptz, so i listed it to be installed in the debian/install file as &#8220;25MBFLAC.file tmp&#8221; and then in my postinst file, i added:</p><p><code>#!/bin/sh<br />mv /tmp/25MBFLAC.file /usr/local/Scriptz/<br /></code></p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/cpandiffscript/'> CPAN Diff script</a> </h2>
      <div class="post-meta">Fri, Dec 16, 2011</div>
    </header>
    <p><img src="http://theslowbullet.files.wordpress.com/2011/01/clonecover.jpg" alt="diff" /></p><p>I put together a quick perl script for comparing installed CPAN modules between two hosts. Find it <a href="https://github.com/sideb0ard/CPANDiff" title="CPANDiff" target="_blank">here</a>.</p><p>Quite easy to use:<br />Usage: ./CompareHostCpanModules.pl login@host1 login@host2</p><p>The script ssh's into both hosts (so it's easier if you have your ssh-keys setup) and grabs a list of installed CPAN modules and versions, then outputs the differences - it returns two lists - one of modules installed but having different versions, and another list of modules missing from the second host. </p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/genxen/'> Gen Xen</a> </h2>
      <div class="post-meta">Mon, Oct 10, 2011</div>
    </header>
    <p><img alt="" width="600" src="http://www.just-marvel-x-men.com/image-files/astonishing-x-men-1-100k.jpg" title="Xen" class="alignnone"  /></p><p>I've been working pretty extensively with Xen and Puppet in my new job, really loving it! I've been creating a whole load of Xen hosts, most of which are cloned from an initial image I built using Xen-tools. I've just finished a script which is over on <a href="https://github.com/sideb0ard/GenXen" title="GitHub" target="_blank">my github page</a>, which basically automates what was previously a manual process.</p><p>Basically, it copies your existing disk.img and swap.img, generates a new xen.cfg file based on some interactive input (desired hostname, IP, memory and number of vCPUs) plus a random Xen mac address, then mounts the disk.img file and changes some appropriate system files - /etc/hostname, hosts, and network/interfaces.</p><p>All quite simple and straight forward, but quite nice to have automated.</p><p><a href="https://github.com/sideb0ard/GenXen" title="GenXen" target="_blank">GenXen</a></p><p>Here's the README:</p><p>GenXen #<br />#############################</p><p>A script for automating Xen VM deployment.</p><p>It requires that you have a base disk.img and swap.img already created.<br />I created mine with:<br />xen-create-image -pygrub -size=50Gb -swap=9Gb -vcpus=2 -memory 6Gb -dist=squeeze -dhcp -passwd -dir=/var/virt-machines -hostname=xen-squeeze-base</p><p>Fill in some of the variables at the top of GenXen.pl before running, then simply:<br />./GenXen.pl</p><p>The interactive part will ask for hostname, memory size, vCPUs, IP address, then generate a unique Xen mac address, and write these all to a xen config file which will be saved in /etc/xen/</p><p>It'll copy your disk.img and swap.img to destination dir, mount the disk.img and create appropriate files for:<br />/etc/hostname<br />/etc/hosts<br />/etc/network/interfaces </p><p>After that you should be good to launch with:</p><p>xm create -c /etc/xen/whatever-your-hostname-is.cfg</p>

</article>

    
        <article class="post">
    <header>
      <h2><a href='http://theb0ardside.com/vagrantandchefsetup/'> Vagrant and Chef setup</a> </h2>
      <div class="post-meta">Fri, Aug 5, 2011</div>
    </header>
    <p>I've been reading through ThoughtWorks' latest &#8216;<a href="http://www.thoughtworks.com/radar" title="radar" target="_blank">technology radar</a>&#8216; which led me to look up <a href="http://vagrantup.com/" title="Vagrant" target="_blank">Vagrant</a>, one of the tools they list as worth exploring.</p><p>Vagrant is a framework for building and deploying Virtual Machine environments, using Oracle VirtualBox for the actual VMs and utilizing Chef for configuration management.  </p><p>Watching through this intro video:</p><p>http://vimeo.com/9976342</p><p>i was quite intrigued as it is very similar to what i was looking to achieve earlier when i was <a href="http://www.theb0ardside.com/?p=22" title="Xen and Puppet" target="_blank">experimenting with installing Xen and configuring with Puppet.</a></p><p>So here's what I experienced during the setup of Vagrant on my Macbook - I decided to start with a simple Chef install to familiarise myself with Chef itself and it's own requirements CouchDB, RabbitMQ and Solr, mostly by following <a href="http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration" title="Chef Manual Install OS X" target="_blank">these instructions</a> - </p><p><strong>-CHEF INSTALL-</strong></p><p><strong>sudo gem install chef<br />sudo gem install ohai<br /></strong></p><p>Chef uses couchDB as it's datastore, so we need to install it using the instructions <a href="http://wiki.apache.org/couchdb/Installing_on_OSX" title="CouchDB install OS X" target="_blank">here</a> </p><p><strong>brew install couchdb</strong></p><p>The instructions I list above also contains steps to install a couchDB user and set it up as a daemon. They didn't work for me, and after 30mins of troubleshooting, i gave up and went with the simpler option of running it under my own user - in production this will be running on a Linux server rather than my Macbook, so it seemed fair enough -</p><p><strong>cp /usr/local/Cellar/couchdb/1.1.0/Library/LaunchDaemons/org.apache.couchdb.plist ~/Library/LaunchAgents/</p><p>launchctl load -w ~/Library/LaunchAgents/org.apache.couchdb.plist</strong></p><p>Check its running okay by going to<br /><a href="http://127.0.0.1:5984/" title="Localhost" target="_blank">http://127.0.0.1:5984/</a></p><p>which should provide something akin to :<br /><strong>{&#8220;couchdb&#8221;:&#8221;Welcome&#8221;,&#8221;version&#8221;:&#8221;1.1.0&#8243;}</strong></p><p><strong>- INSTALL RABBITMQ -</strong></p><p><strong>brew install rabbitmq<br />/usr/local/sbin/rabbitmq-server -detached</p><p>sudo rabbitmqctl add_vhost /chef<br />sudo rabbitmqctl add_user chef testing<br />sudo rabbitmqctl set_permissions -p /chef chef &#8220;.*&#8221; &#8220;.*&#8221; &#8220;.*&#8221;<br /></strong></p><p>Ok, Gettin' back to my mission, break out the whipped cream and the cherries, then I go through all the fly positions - oh, wrong mission! </p><p>Ok..</p><p><strong>brew install gecode<br />brew install solr</p><p>sudo gem install chef-server chef-server-api chef-server chef-solr<br />sudo gem install chef-server-webui<br />sudo chef-solr-installer<br /></strong></p><p>Setup a conf file -<br /><strong>sudo mkdir /etc/chef<br />sudo vi /etc/chef/server.rb</strong> - paste in the example from:</p><p><a href="http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration" title="chef conf" target="_blank">http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration</a> - making the appropriate changes for your FQDN</p><p>At this point, the above instructions ask you to start the indexer however the instructions haven't been updated to reflect changes to Chef version 0.10.2 in which chef-solr-indexer has been replaced with chef-expander</p><p>So, instead of running:<br /><strong>sudo chef-solr-indexer </strong></p><p>you instead need to run:<br /><strong>sudo chef-expander -n1 -d<br /></strong></p><p>Next i tried<br /><strong>sudo chef-solr</strong></p><p>which ran into<br /><em>&#8220;`configure_chef': uninitialized constant Chef::Application::SocketError (NameError)&#8221;</em></p><p>i had to create an <strong>/etc/chef/solr.rb</strong> file and simply add this to the file:</p><p><strong>require &#8216;socket'</strong> </p><p>startup now worked -<br />if you want to daemonize it, use:</p><p><strong>sudo chef-solr -d</strong></p><p>Next start Chef Server with:<br /><strong>sudo chef-server -N -e production -d</strong></p><p>and finally:<br /><strong>sudo chef-server-webui -p 4040 -e production</strong></p><p>Now you should be up and running - you need to configure the command client &#8216;Knife' follwing the instructions <a href="http://wiki.opscode.com/display/chef/Manual+Chef+Server+Configuration" title="Knife setup" target="_blank">here</a> - under the section &#8216;<strong>Configure the Command Line Client</strong>&#8216;</p><p><strong>mkdir -p ~/.chef<br />sudo cp /etc/chef/validation.pem /etc/chef/webui.pem ~/.chef<br />sudo chown -R $USER ~/.chef</p><p>knife configure -i</strong></p><p>(follow the instructions at the link - you only need to change the location of the two pem files you copied above)</p><p>Ok, so hopefully you're at the same place as me with this all working at least as far as being able to log into CouchDB, and verifying that Chef/Knife are both working.</p><p><strong>- VAGRANT SETUP -</strong></p><p>Now, onward with the original task of Vagrant setup&#8230;<br />Have a read over the <a href="http://vagrantup.com/docs/getting-started/index.html " title="Vagrant Getting Started" target="_blank">getting started guide:</a></p><p>Install VirtualBox - download from <a href="http://www.virtualbox.org/wiki/Downloads" title="VirtualBox" target="_blank">http://www.virtualbox.org/wiki/Downloads</a></p><p>Run the installer, which should all work quite easily. Next..</p><p><strong>gem install vagrant</p><p>mkdir vagrant_guide<br />cd vagrant_guide/<br />vagrant init</strong></p><p>this creates the base Vagrantfile, which the documentation compares to a Makefile, basically a reference file for the project to work with.</p><p>Setup our first VM -<br /><strong>vagrant box add lucid32 http://files.vagrantup.com/lucid32.box</strong></p><p>This is downloaded and saved in ~/.vagrant.d/boxes/ </p><p>edit the Vagrantfile which was created and change the &#8220;box&#8221; entry to be &#8220;lucid32&#8243;, the name of the file we just saved. </p><p>Bring it online with:<br /><strong>vagrant up</strong></p><p>then ssh into with<br /><strong>vargrant ssh</strong></p><p>Ace, that worked quite easily. After a little digging around, I  logged out and tore the machine down again with<br /><strong>vagrant destroy</strong></p><p><strong>- TYING IT ALL TOGETHER -</strong><br />Now we need to connect our Vagrant install with our Chef server</p><p>First, clone the Chef repository with:<br /><strong>git clone git://github.com/opscode/chef-repo.git </strong></p><p>add this dir to your <strong>~/.chef/knife.rb</strong> file<br />i.e<br /><strong>cookbook_path           ["/Users/thorstensideboard/chef-repo/cookbooks"]</strong></p><p>Download the Vagrant cookbook they use in their examples -</p><p><strong>wget http://files.vagrantup.com/getting_started/cookbooks.tar.gz<br />tar xzvf cookbooks.tar.gz<br />mv cookbooks/* chef-repo/cookbooks/<br /></strong></p><p>Add it to our Chef server using Knife:<br /><strong>knife cookbook upload -a</strong><br />(knife uses the cookbook_path we setup above)</p><p>If you browse to your localhost at<br /><strong>http://sbd-ioda.local:4040/cookbooks/</strong><br />you should see the three new cookbooks which have been added.</p><p>Now to edit Vagrantfile and add your Chef details:<br /><code><br />Vagrant::Config.run do |config|</p><p>    config.vm.box = "lucid32"</p><p>    config.vm.provision :chef_client do |chef|</p><p>    chef.chef_server_url = "http://SBD-IODA.local:4000"<br />    chef.validation_key_path = "/Users/thorsten/.chef/validation.pem"<br />    chef.add_recipe("vagrant_main")<br />    chef.add_recipe("apt")<br />    chef.add_recipe("apache2")</p><p>    end<br />end<br /></code></p><p>I tried to load this up with<br /><strong>vagrant up</strong><br />however received:</p><blockquote><p>&#8220;[default] [Fri, 05 Aug 2011 09:27:07 -0700] INFO: *** Chef 0.10.2 ***<br />: stdout<br />[default] [Fri, 05 Aug 2011 09:27:07 -0700] INFO: Client key /etc/chef/client.pem is not present - registering<br />: stdout<br />[default] [Fri, 05 Aug 2011 09:27:28 -0700] FATAL: Stacktrace dumped to /srv/chef/file_store/chef-stacktrace.out<br />: stdout<br />[default] [Fri, 05 Aug 2011 09:27:28 -0700] FATAL: SocketError: Error connecting to http://SBD-IODA.local:4000/clients - getaddrinfo: Name or service not known&#8221;</p></blockquote><p>I figured this was a networking issue, and yeah, within the VM it has no idea of my Macbook's local hostname, which i fixed by editing its /etc/hosts file and manually adding it.</p><p>Upon issuing a<br /><strong>vagrant reload</strong>, boom! you can see the Vagrant host following the recipes and loading up a bunch of things including apache2</p><p>However at this point, you can still only access it's webserver from within the VM, so in order to access it from our own desktop browser, we can add the following line to the Vagrantfile:<br /><strong>config.vm.forward_port(&#8220;web&#8221;, 80, 8080)</strong></p><p>After another reload, you should now be able to connect to localhost:8080 and access your new VM's apache host.</p><p>In order to use this setup in any sort of dev environment will still need a good deal more work, but for the moment, this should be enough to get you up and running and able to explore both Vagrant and Chef. </p>

</article>

    
  </div>
</section>

      <script src="http://theb0ardside.com/static/js/jquery.js"></script>
      <script src="http://theb0ardside.com/static/js/bootstrap.min.js"></script>
      <script src="http://theb0ardside.com/static/js/mousetrap.min.js"></script>
      <script src="http://theb0ardside.com/static/js/b0ardside.js"></script>
      </div>
      </div>
      <div id="footer"></div>
  </body>

</html>

